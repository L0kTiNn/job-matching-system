"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –£–ú–ù–´–• —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è –≤—Å–µ—Ö —Ä–µ–∑—é–º–µ –∏ –≤–∞–∫–∞–Ω—Å–∏–π
–í–ï–†–°–ò–Ø 2.0: multilingual –º–æ–¥–µ–ª—å (768 –∏–∑–º–µ—Ä–µ–Ω–∏–π) + —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –Ω–∞–≤—ã–∫–æ–≤!
"""

import sys
sys.path.append('.')

from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import psycopg2
import numpy as np

# ============= –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø =============

DB_CONFIG = {
    "host": "localhost",
    "database": "job_matching_system",
    "user": "postgres",
    "password": "diploma2025"
}

# Multilingual –º–æ–¥–µ–ª—å —Å 768 –∏–∑–º–µ—Ä–µ–Ω–∏—è–º–∏
MODEL_NAME = 'paraphrase-multilingual-mpnet-base-v2'

# ============= –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø =============

print("=" * 60)
print(" –ü–†–û–ö–ê–ß–ê–ù–ù–ê–Ø –ì–ï–ù–ï–†–ê–¶–ò–Ø –≠–ú–ë–ï–î–î–ò–ù–ì–û–í V2.0")
print("=" * 60)
print(f"\n –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏: {MODEL_NAME}...")

model = SentenceTransformer(MODEL_NAME)
print(" –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞!\n")

# ============= –§–£–ù–ö–¶–ò–ò =============

def get_db_connection():
    """–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î"""
    return psycopg2.connect(**DB_CONFIG)

def normalize_skill(skill: str) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –Ω–∞–≤—ã–∫–∞"""
    return skill.lower().strip()

def generate_skill_embeddings():
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è –ö–ê–ñ–î–û–ì–û —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ –Ω–∞–≤—ã–∫–∞"""

    conn = get_db_connection()
    cur = conn.cursor()

    print("=" * 60)
    print("–≠–¢–ê–ü 1: –ì–ï–ù–ï–†–ê–¶–ò–Ø –≠–ú–ë–ï–î–î–ò–ù–ì–û–í –ù–ê–í–´–ö–û–í")
    print("=" * 60)

    # –°–æ–±–∏—Ä–∞–µ–º –í–°–ï —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –Ω–∞–≤—ã–∫–∏
    all_skills = set()

    # –ò–∑ —Ä–µ–∑—é–º–µ
    cur.execute("SELECT skills FROM resumes WHERE skills IS NOT NULL")
    for (skills_str,) in cur.fetchall():
        if skills_str:
            skills = [normalize_skill(s.strip()) for s in skills_str.split(',') if s.strip()]
            all_skills.update(skills)

    # –ò–∑ –≤–∞–∫–∞–Ω—Å–∏–π
    cur.execute("SELECT requirements FROM vacancies WHERE requirements IS NOT NULL")
    for (req_str,) in cur.fetchall():
        if req_str:
            skills = [normalize_skill(s.strip()) for s in req_str.split(',') if s.strip()]
            all_skills.update(skills)

    print(f"\n –ù–∞–π–¥–µ–Ω–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –Ω–∞–≤—ã–∫–æ–≤: {len(all_skills)}\n")

    # –°–æ–∑–¥–∞—ë–º —Ç–∞–±–ª–∏—Ü—É –µ—Å–ª–∏ –Ω–µ—Ç
    cur.execute("""
        CREATE TABLE IF NOT EXISTS skill_embeddings (
            id SERIAL PRIMARY KEY,
            skill_text VARCHAR(255) NOT NULL UNIQUE,
            embedding VECTOR(768) NOT NULL,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """)

    # –°–æ–∑–¥–∞—ë–º –∏–Ω–¥–µ–∫—Å—ã
    cur.execute("""
        CREATE INDEX IF NOT EXISTS idx_skill_embeddings_text 
        ON skill_embeddings(skill_text)
    """)

    conn.commit()

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
    processed = 0
    for skill in sorted(all_skills):
        try:
            embedding = model.encode(skill)
            embedding_list = embedding.tolist()

            cur.execute("""
                INSERT INTO skill_embeddings (skill_text, embedding)
                VALUES (%s, %s)
                ON CONFLICT (skill_text) DO NOTHING
            """, (skill, embedding_list))

            processed += 1

            if processed % 10 == 0:
                print(f" –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed}/{len(all_skills)}")

        except Exception as e:
            print(f" –û—à–∏–±–∫–∞ –¥–ª—è –Ω–∞–≤—ã–∫–∞ '{skill}': {e}")

    conn.commit()
    cur.close()
    conn.close()

    print(f"\n –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã –¥–ª—è {len(all_skills)} –Ω–∞–≤—ã–∫–æ–≤!\n")

def generate_resume_embeddings():
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è —Ä–µ–∑—é–º–µ"""

    conn = get_db_connection()
    cur = conn.cursor()

    print("=" * 60)
    print("–≠–¢–ê–ü 2: –ì–ï–ù–ï–†–ê–¶–ò–Ø –≠–ú–ë–ï–î–î–ò–ù–ì–û–í –†–ï–ó–Æ–ú–ï")
    print("=" * 60)

    cur.execute("SELECT id, title, skills FROM resumes")
    resumes = cur.fetchall()
    print(f"\n –ù–∞–π–¥–µ–Ω–æ —Ä–µ–∑—é–º–µ: {len(resumes)}\n")

    for i, (resume_id, title, skills_str) in enumerate(resumes, 1):
        print(f"[{i}/{len(resumes)}] –†–µ–∑—é–º–µ ID={resume_id}: {title}")

        if skills_str:
            skills = [s.strip() for s in skills_str.split(',') if s.strip()]
            skill_embeddings = [model.encode(normalize_skill(s)) for s in skills]

            if skill_embeddings:
                resume_embedding = np.mean(skill_embeddings, axis=0)
            else:
                resume_embedding = model.encode(title)
        else:
            resume_embedding = model.encode(title)

        cur.execute("""
            UPDATE resumes
            SET embedding = %s
            WHERE id = %s
        """, (resume_embedding.tolist(), resume_id))

        print(f"   –≠–º–±–µ–¥–¥–∏–Ω–≥ —Å–æ—Ö—Ä–∞–Ω—ë–Ω (—Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {resume_embedding.shape})\n")

    conn.commit()
    cur.close()
    conn.close()

    print(f" –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ä–µ–∑—é–º–µ: {len(resumes)}\n")

def generate_vacancy_embeddings():
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è –≤–∞–∫–∞–Ω—Å–∏–π"""

    conn = get_db_connection()
    cur = conn.cursor()

    print("=" * 60)
    print("–≠–¢–ê–ü 3: –ì–ï–ù–ï–†–ê–¶–ò–Ø –≠–ú–ë–ï–î–î–ò–ù–ì–û–í –í–ê–ö–ê–ù–°–ò–ô")
    print("=" * 60)

    cur.execute("SELECT id, title, requirements FROM vacancies")
    vacancies = cur.fetchall()
    print(f"\nüíº –ù–∞–π–¥–µ–Ω–æ –≤–∞–∫–∞–Ω—Å–∏–π: {len(vacancies)}\n")

    for i, (vacancy_id, title, requirements_str) in enumerate(vacancies, 1):
        print(f"[{i}/{len(vacancies)}] –í–∞–∫–∞–Ω—Å–∏—è ID={vacancy_id}: {title}")

        if requirements_str:
            skills = [s.strip() for s in requirements_str.split(',') if s.strip()]
            skill_embeddings = [model.encode(normalize_skill(s)) for s in skills]

            if skill_embeddings:
                vacancy_embedding = np.mean(skill_embeddings, axis=0)
            else:
                vacancy_embedding = model.encode(title)
        else:
            vacancy_embedding = model.encode(title)

        cur.execute("""
            UPDATE vacancies
            SET embedding = %s
            WHERE id = %s
        """, (vacancy_embedding.tolist(), vacancy_id))

        print(f"   –≠–º–±–µ–¥–¥–∏–Ω–≥ —Å–æ—Ö—Ä–∞–Ω—ë–Ω (—Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {vacancy_embedding.shape})\n")

    conn.commit()
    cur.close()
    conn.close()

    print(f" –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –≤–∞–∫–∞–Ω—Å–∏–π: {len(vacancies)}\n")

def test_skill_matching():
    """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —É–º–Ω–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –Ω–∞–≤—ã–∫–æ–≤"""

    print("=" * 60)
    print("–¢–ï–°–¢: –£–ú–ù–û–ï –°–†–ê–í–ù–ï–ù–ò–ï –ù–ê–í–´–ö–û–í")
    print("=" * 60)

    test_pairs = [
        ("machine learning", "–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ"),
        ("python", "–ø–∏—Ç–æ–Ω"),
        ("docker", "–¥–æ–∫–µ—Ä"),
        ("javascript", "–¥–∂–∞–≤–∞—Å–∫—Ä–∏–ø—Ç"),
        ("data science", "–Ω–∞—É–∫–∞ –æ –¥–∞–Ω–Ω—ã—Ö"),
        ("python", "java"),
        ("react", "vue"),
    ]

    print("\n –¢–µ—Å—Ç–æ–≤—ã–µ –ø–∞—Ä—ã:\n")

    for skill1, skill2 in test_pairs:
        emb1 = model.encode(skill1)
        emb2 = model.encode(skill2)

        similarity = cosine_similarity([emb1], [emb2])[0][0]
        match = " –°–û–í–ü–ê–î–ê–Æ–¢" if similarity >= 0.75 else " –†–ê–ó–ù–´–ï"

        print(f"{skill1:25} ‚Üî {skill2:25} | {similarity:.2%} | {match}")

    print()

def test_recommendations():
    """–¢–µ—Å—Ç —Å–∏—Å—Ç–µ–º—ã —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"""

    conn = get_db_connection()
    cur = conn.cursor()

    print("=" * 60)
    print("–¢–ï–°–¢: –°–ò–°–¢–ï–ú–ê –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ô")
    print("=" * 60)

    try:
        cur.execute("SELECT id, title, skills FROM resumes LIMIT 1")
        resume = cur.fetchone()

        if not resume:
            print("\n –ù–µ—Ç —Ä–µ–∑—é–º–µ –≤ –ë–î")
            return

        resume_id, title, skills = resume

        print(f"\n –†–µ–∑—é–º–µ: {title}")
        print(f"   –ù–∞–≤—ã–∫–∏: {skills or '–ù–µ —É–∫–∞–∑–∞–Ω—ã'}\n")

        cur.execute("""
            SELECT 
                v.id, v.title, v.requirements, v.location,
                v.salary_min, v.salary_max,
                1 - (v.embedding <=> r.embedding) as similarity
            FROM vacancies v, resumes r
            WHERE r.id = %s
            ORDER BY v.embedding <=> r.embedding
            LIMIT 10
        """, (resume_id,))

        results = cur.fetchall()

        if not results:
            print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ—Ö–æ–∂–∏—Ö –≤–∞–∫–∞–Ω—Å–∏–π")
            return

        print(f" –ù–∞–π–¥–µ–Ω–æ {len(results)} –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –≤–∞–∫–∞–Ω—Å–∏–π:\n")

        for i, (vac_id, vac_title, reqs, loc, sal_min, sal_max, sim) in enumerate(results, 1):
            print(f"{i}. {vac_title}")
            print(f"   –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ: {sim * 100:.1f}%")
            if reqs:
                print(f"   –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è: {reqs[:60]}...")
            if loc:
                print(f"   –õ–æ–∫–∞—Ü–∏—è: {loc}")
            if sal_min or sal_max:
                salary = f"{sal_min or '–æ—Ç'} - {sal_max or '–¥–æ'} —Ä—É–±."
                print(f"   –ó–∞—Ä–ø–ª–∞—Ç–∞: {salary}")
            print()

    finally:
        cur.close()
        conn.close()

# ============= –ì–õ–ê–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø =============

def main():
    """–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö —ç—Ç–∞–ø–æ–≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏"""

    try:
        generate_skill_embeddings()
        generate_resume_embeddings()
        generate_vacancy_embeddings()

        print("=" * 60)
        print(" –ì–ï–ù–ï–†–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê –£–°–ü–ï–®–ù–û!")
        print("=" * 60)

        test_skill_matching()
        test_recommendations()

    except Exception as e:
        print(f"\n –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
